{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPbCukOSEkChLnCwhu1n2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakes1811/Smart-Waste-Segregation-System/blob/main/WebCam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9tcVHMhJDBg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model(\"C:\\\\Users\\\\jenif\\\\Downloads\\\\waste_classifier_mobilenet.h5\")\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "labels = ['Cardboard', 'E waste', 'Glass','Metal', 'Paper', 'Plastic']\n",
        "\n",
        "# Open webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "         # Preprocess frame\n",
        "    img = cv2.resize(frame, (128,128))\n",
        "\n",
        "    # Convert to grayscale and apply histogram equalization\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    equalized = cv2.equalizeHist(gray)\n",
        "    # Convert back to 3-channel image\n",
        "    img = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)\n",
        "    img = img.astype(\"float32\")/255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "    # Predict\n",
        "    predictions = model.predict(img)\n",
        "    predicted_class= np.argmax(predictions)\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    label = f\"{labels[predicted_class]}({confidence:.2f})\"\n",
        "\n",
        "    # Display result\n",
        "    cv2.putText(frame, f'Waste: {label}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "    cv2.imshow(\"Waste Classification\", frame)\n",
        "\n",
        "    # Press 'q' to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Verify the class order from your training process\n",
        "print(train_generator.class_indices)"
      ]
    }
  ]
}